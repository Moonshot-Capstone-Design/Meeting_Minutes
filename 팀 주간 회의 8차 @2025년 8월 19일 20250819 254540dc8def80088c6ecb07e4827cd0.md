# 팀 주간 회의 8차 @2025년 8월 19일 20250819

날짜: 2025년 8월 16일
유형: 팀 주간 회의
AI 요약: 자율주행 로봇 개발을 위한 회의에서 GPS 없는 환경에서의 위치 추적 기술, 예산 및 하드웨어 옵션, 다양한 응용 분야 제안이 논의되었으며, 다목적 활용을 통한 비용 효율성 확보의 중요성이 강조되었습니다.

요약

###

메모

		

## 업데이트

### <햅틱컬 스마트 BOX>

![그림2.png](%EA%B7%B8%EB%A6%BC2.png)

- 박스 안에는 카메라들이 2~3개 위치
- 카메라를 이용해서 손 모양의 스켈레톤 모델 생성
- 스켈레톤 모델을 통한 포인트를 연동해서 디지털 차원으로 옮김 → **디지털 트윈, VrXr**
- 다른 차원(모니터)상에 있는 오브젝트를 만지면 햅틱 센서를 통해 손에 직접적인 감각을 느낄 수 있도록 함
- 장갑이나 다른 센서들도 활용
- 라즈베리파이를 이용하여 **영상처리** 및 다양한 AI 모델 진행
- 박스 Or 디바이스처럼 만들어서 노트북이나 컴퓨터에 꼽기만 하면 사용 가능하도록 → On Device 형식

### <모방 학습을 통한 사용자 모델 추출>

- 정부기관이나 다른 회사에서 게임 등록
- 게임을 해서 뭐시기 뭐시기 하면 보상 습득
- 다양한 사람이 하기 때문에 데이터 수집 가능
- 우리가 하기엔 살짝 부적합하다는 의견

---

## <리:프레임>

- 만든다면 모듈 형식 → 사용자가 여행하면서 가지고 다닐 수 있도록 함 → 여행하며 가지고 다니면 해당 모듈이 사용자의 주변 환경을 기록

**데이터 수집 단계**

- 생체 센서 : 여행 중 심박수&피부 전도도(GSR) 기록 → 감정 반응 높은 구간 자동 트래킹
- LiDAR 스캐너 사용 : 지형/건물 구조까지 일부 3D 스캔

**AI 기반 씬 재구성**

- 융합 : 360도 영상 + GPS/IMU + 환경 센서 + 음성 메모 → 멀티 모달
- Transformer가 시간&공간 맥락을 톨합
- Style Transfer : 실제 영상 기반 + AI 보간(Stable Video Diffusion)으로 화질/프레임 보강
- Semantic Scene Graph : Unity 내부에서 “산 → 나무 흔들림 + 새 소리” 식으로 오브젝트 그래프 구성 → 이후 물리 효과 연동

**감각 피드백 확장**

- 멀티센서 출력:
    - 바람: 팬
    - 향기: 디퓨저
    - 햇빛/온기: IR 히터
    - 진동: 웨어러블 진동밴드
- 맞춤 감각 매핑: 사용자가 기억 속에서 중요하게 느낀 감각(“여기선 바람이 인상적이었다”)을 태깅 → 회상 시 강조

**만약 Genie 3를 활용한다면?**

데이터 → VR 월드 자동화

- 여행 후 기록된 데이터를 텍스트/이미지 프롬프트로 변환:
    - “2025년 3월 15일, 교토 아라시야마 대숲, 바람이 불고 새들이 지저귀는 장면”
        
        → Genie 3가 즉시 기본 씬을 생성.
        
- 이후 Unity/Unreal에서 기록된 실제 데이터(360도 영상·센서값)를 덮어씌워 정밀화.

빠른 프로토타이핑

- Genie 3는 프롬프트 → 세계 모델 생성 → VR 탐험 루프.
- 사용자가 여행 데이터를 업로드하기 전에도 샘플 회상 여행을 생성 가능.

보간·보완용

- 촬영 데이터가 부족하거나 손상된 구간 → Genie 3가 프롬프트 기반으로 자연스럽게 메꿔줌.
    
    (예: 비 오는 날 렌즈에 물방울 → Genie 3가 맥락상 깨끗한 대숲 장면으로 복원)
    

개인화 AI 가이드

- Genie 3의 promptable event 기능 활용:
    - 사용자가 VR 속에서 “그때 들었던 빗소리를 다시 틀어줘” → 즉시 환경음 생성/재생.
    - “여행 당시 엄마랑 대화했던 순간 보여줘” → 음성 기록 + NPC 애니메이션으로 재현.

### **[여행 기록 모듈]**

**영상/공간 기록 장치**

- 360° 카메라
    - Insta360 X3, GoPro Max, Ricoh Theta X
    - 여행자의 시야와 주변 환경을 전방위로 캡처
    - Genie 3가 이 영상을 기반으로 씬의 기본 레이아웃을 재구성 가능
- 스테레오 카메라 / 깊이 센서 (선택)
    - Intel RealSense, iPhone LiDAR
    - 구조적 공간 정보까지 얻어 Unity/Genie 씬에 정확히 반영

**위치/동작 추적 장치**

- GPS 모듈
    - 스마트폰 내장 GPS 또는 별도 고정밀 GNSS 모듈 (u-blox 등)
    - 여행 경로와 특정 포인트 매핑
- IMU (Inertial Measurement Unit)
    - 9축 센서 (가속도 + 자이로 + 자기계)
    - 카메라의 방향/고개 움직임/속도 기록 → Genie 3에 시선 방향 입력
- 동기화 기기
    - ESP32 / Arduino + RTC(Real Time Clock)
    - 모든 센서와 영상 데이터를 시간 축 기준으로 정렬

**음향/환경 기록 장치**

- 바이노럴 마이크
    - 실제 위치감 있는 소리를 VR 씬에 반영
    - Genie 3는 promptable event로 소리(예: 새 지저귐, 빗소리)를 증강 가능
- 환경 센서 (옵션)
    - 온도·습도·풍속·조도 센서
    - Genie 3에게 “상황 맥락” 제공 → 바람 효과·날씨 시뮬레이션 자동 생성

**사용자 경험 기록**

- Wearable 생체센서 (선택)
    - 스마트워치/밴드로 심박수, GSR(피부전도도) 측정
    - Genie 3가 “감정 강도 높은 순간” 강조 VR 이벤트 생성
- 음성 메모 장치
    - 여행자가 즉석에서 녹음 (“여긴 내가 10년 만에 다시 온 곳”)
    - VR 씬 안에서 본인 목소리 가이드로 재생

**저장 및 전송 모듈**

- 로컬 저장: SD카드 (고화질 영상 때문에 1TB 이상 권장)
- 실시간 업로드 (선택): LTE/5G 모듈 → 클라우드 저장
- 메타데이터 DB: (시간·위치·센서 값·음성 메모) → Genie 3가 월드 생성 시 레퍼런스로 사용

**사용자가 VR 안에서 “그때 바람 더 강하게 불어줘” → Genie 3가 promptable event로 즉시 반영**

---

## <냉장고를 부탁해>

**필요 장비**

- 카메라 모듈
    - Raspberry Pi 카메라
    - Intel RealSense
    - 일반 USB 카메라
        
        → 식재료의 종류와 상태(색, 크기, 부패 여부)를 AI 모델로 판별
        
- 가스 센서 (MQ 시리즈)
    - MQ-2, MQ-135 → 부패 시 발생하는 암모니아, 황화 수소, 에탄올 등 감지
- 무게 센서 (로드셀 + HX711 모듈)
    - 식재료 사용량 추적 (예: 우유 팩 남은 양)
- RFID / NFC 태그
    - 구매 시 태그 부착 → 유통기한 자동 등록

**냉장고 내부 위치 표시** 

- 소형 레이저 모듈 or RGB LED Strip (WS2812B, Neopixel)
    - AI가 특정 재료 위치를 인식하면, 해당 위치에 불빛/레이저로 표시
- 음성 안내 모듈 (스피커 + TTS 엔진)
    - “토마토는 오른쪽 중간 선반에 있습니다.” → 음성 피드백

**사용자 인터페이스**

- 터치 디스플레이 (7인치 터치스크린, Raspberry Pi HAT형 등)
    - 냉장고 앞에 부착, 재료 현황 및 레시피 표시
- 모바일 앱 / 웹 대시보드
    - 냉장고 내부 상태를 스마트폰으로 확인 가능
- 마이크 + 음성 인식 (ESP32 + Google Speech API / 오픈소스 STT)
    - “오늘 저녁에 뭐 해 먹을까?” → AI가 레시피 추천

**컨트롤러 / 중앙 처리 장치**

- Raspberry Pi 5 / Jetson Nano
    - 카메라 + AI 추론 + DB 관리 + UI 제공
- Arduino / ESP32
    - 센서 제어(가스, 무게, LED, 레이저) 및 데이터 전송

**소프트웨어 & AI 스택**

1. 식재료 인식
    - YOLOv8, Detectron2 → 냉장고 내부 카메라로 재료 인식
    - OCR (Tesseract) → 포장지 유통기한 문자 인식
2. 부패 탐지
    - 가스 센서 수치 기반 + AI 분류 모델
    - 이미지 기반 색 변화 분석 (예: 곰팡이, 변색)
3. 재료 DB & 추천
    - SQLite/MySQL → 재료명, 수량, 유통기한, 상태 저장
    - 레시피 API (예: Spoonacular API, 한국식 레시피 DB 연동)
    - Rule-based + 추천 알고리즘
        - 기한 임박 재료 우선 사용
        - 부족한 재료 리스트업
4. 건강 맞춤형 레시피
    - 사용자 프로필 (칼로리 목표, 알레르기, 질환, 선호 음식)
    - AI가 “저염식 / 고단백 / 다이어트” 맞춤 레시피 추천
5. UI/UX
    - 웹 대시보드 (React, Flask/Django 백엔드)
    - 모바일 앱 (Flutter/React Native)
    - 냉장고 앞 디스플레이 (Raspberry Pi Kiosk 모드)

**구현 흐름**

1. 데이터 수집
    - 카메라 + RFID/NFC → 재료 종류, 유통기한 기록
    - 무게 센서 + 가스 센서 → 재료 상태 업데이트
2. AI 분석
    - YOLOv8으로 실시간 재료 인식
    - DB에 저장 및 상태 갱신
3. 사용자 요청
    - 음성 “오늘 저녁 추천해줘” → AI가 기한 임박 재료 기반 레시피 추천
4. 위치 안내
    - “토마토가 필요합니다” → 해당 칸 LED 점등 or 레이저 포인팅
5. 출력
    - 디스플레이: 부족한 재료, 추천 요리, 건강 분석
    - 모바일 앱 or 진짜 리스트 뽑아줌: 장보기 리스트 자동 생성

---

### <선로 결빙 탐지 및 열감지 모듈>

- 염화 칼슘을 뿌려 결빙을 푸는 방식
- 선로 결빙뿐만이 아니라, 사고 예방을 하는 용도로 미리미리 결빙을 방지하도록 설계하면 어떨까 싶음 → 이 부분은 AI 학습
- 여름에는 선로의 잡초 제거를 한다면?
- 태양광 패널이나 열 저장 장치(PCM)를 이용해서, 에너지를 저장했다가 밤에 결빙이 일어나면 밤에 미리 작업을 하여 방지를 할 수 있도록 함

---

### <지금까지 이런 공포게임은 없었다. 이것은 게임인가 현실인가>

- DRS 센서를 이용해서 땀을 흘리면 더 공포감 있도록 설정
- 마이크 기반 센서를 이용해서 소리를 일정 데시벨 이상 내면 괴물한테 들키고, 숨을 참으면 은신이 되는 식으로 함.
- 저가형 VR 기기를 사용해서 더욱 몰입감 있게 플레이.

---

### <RFID를 통한 스마트 주행 로봇>

- 센서 퓨전을 통해 Localization을 한다면?

### <야, 해줘. 쇼핑카트>

- 앱으로 내가 살 물건을 등록한다면, 카트가 마트 내부를 알아서 돌아다니면서 등록된 물품을 담음
- 이것을 할 경우 물건을 집어줄 모듈이 있어야 함

## 할 일

- [x]  선정 된 아이디어 중 인당 2개씩 선정하여 구체화 or 다른 방향으로 개선된 아이디어 생각해오기
- [ ]  다음 회의 : 금요일 오후 10시